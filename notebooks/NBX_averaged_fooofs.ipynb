{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62651/3321975988.py:2: DeprecationWarning: \n",
      "The `fooof` package is being deprecated and replaced by the `specparam` (spectral parameterization) package.\n",
      "This version of `fooof` (1.1) is fully functional, but will not be further updated.\n",
      "New projects are recommended to update to using `specparam` (see Changelog for details).\n",
      "  import fooof\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import fooof\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import pickle\n",
    "import saflow\n",
    "import saflow\n",
    "import os.path as op\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import mne_bids\n",
    "import mne\n",
    "from sklearn.model_selection import permutation_test_score, LeaveOneGroupOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import fooof\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import random\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from saflow.utils import create_fnames\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2781080467.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    return psd_raw, psd_corrected, psd_model_fit\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def load_trial_psd(fooof_path):\n",
    "    for sub in os.listdir(fooof_path)[1:]:\n",
    "        for run in saflow.BLOCS_LIST:\n",
    "            run = '0' + str(run)\n",
    "            fname = op.join(fooof_path, sub, 'meg', f'{sub}_task-gradCPT_run-{run}_meg.pkl')\n",
    "            with open(fname, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            \n",
    "            for trial_idx in range(len(data['fooof_trials'])):\n",
    "                \n",
    "                \n",
    "    return psd_raw, psd_corrected, psd_model_fit\n",
    "psd_raw, psd_corrected, psd_model_fit = load_trial_psd(feature_fpath)\n",
    "\n",
    "#def load_subject_psd(fooof_path):\n",
    "    #return psd_raw, psd_corrected, psd_model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Adding trial 0 of run 03 of subject sub-04\n",
      "Adding trial 1 of run 03 of subject sub-04\n",
      "Adding trial 2 of run 03 of subject sub-04\n",
      "Adding trial 3 of run 03 of subject sub-04\n",
      "Adding trial 4 of run 03 of subject sub-04\n",
      "Adding trial 5 of run 03 of subject sub-04\n",
      "Adding trial 6 of run 03 of subject sub-04\n",
      "Adding trial 7 of run 03 of subject sub-04\n",
      "Adding trial 8 of run 03 of subject sub-04\n",
      "Adding trial 9 of run 03 of subject sub-04\n",
      "Adding trial 10 of run 03 of subject sub-04\n",
      "Adding trial 11 of run 03 of subject sub-04\n",
      "Adding trial 12 of run 03 of subject sub-04\n",
      "Adding trial 13 of run 03 of subject sub-04\n",
      "Adding trial 14 of run 03 of subject sub-04\n",
      "Adding trial 15 of run 03 of subject sub-04\n",
      "Adding trial 16 of run 03 of subject sub-04\n",
      "Adding trial 17 of run 03 of subject sub-04\n",
      "Adding trial 18 of run 03 of subject sub-04\n",
      "Adding trial 19 of run 03 of subject sub-04\n",
      "Adding trial 20 of run 03 of subject sub-04\n",
      "Adding trial 21 of run 03 of subject sub-04\n",
      "Adding trial 22 of run 03 of subject sub-04\n",
      "Adding trial 23 of run 03 of subject sub-04\n",
      "Adding trial 24 of run 03 of subject sub-04\n",
      "Adding trial 25 of run 03 of subject sub-04\n",
      "Adding trial 26 of run 03 of subject sub-04\n",
      "Adding trial 27 of run 03 of subject sub-04\n",
      "Adding trial 28 of run 03 of subject sub-04\n",
      "Adding trial 29 of run 03 of subject sub-04\n",
      "Adding trial 30 of run 03 of subject sub-04\n"
     ]
    }
   ],
   "source": [
    "feature = 'fooof'\n",
    "feature_fpath = op.join(saflow.BIDS_PATH, 'derivatives', feature)\n",
    "\n",
    "\n",
    "for sub in os.listdir(feature_fpath):\n",
    "    \n",
    "    for run in saflow.BLOCS_LIST:\n",
    "        run = '0' + str(run)\n",
    "        fname = op.join(feature_fpath, sub, 'meg', f'{sub}_task-gradCPT_run-{run}_meg.pkl')\n",
    "        fname_output = fname.replace('.pkl', '_magic.pkl')\n",
    "        if not op.exists(fname_output):\n",
    "            magic_dict = []\n",
    "            with open(fname, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            print(magic_dict)\n",
    "            for trial_idx in range(len(data['trial_fooofs'])):\n",
    "                #bad_epoch = data['info'][trial_idx]['bad_epoch']\n",
    "                #trial_type = data['info'][trial_idx]['task']\n",
    "                INOUT = data['info'][trial_idx]['INOUT']\n",
    "\n",
    "            \n",
    "                print(f'Adding trial {trial_idx} of run {run} of subject {sub}')\n",
    "                for chan_idx in range(len(data['trial_fooofs'][trial_idx])):\n",
    "                    psd_raw = data['trial_fooofs'][trial_idx].get_fooof(chan_idx).power_spectrum\n",
    "\n",
    "                    if INOUT == 'IN':\n",
    "                        psd_corrected = data['trial_fooofs'][trial_idx].get_fooof(chan_idx).power_spectrum - data['IN_fooofs'].get_fooof(chan_idx)._ap_fit\n",
    "                    elif INOUT == 'OUT':\n",
    "                        psd_corrected = data['trial_fooofs'][trial_idx].get_fooof(chan_idx).power_spectrum - data['OUT_fooofs'].get_fooof(chan_idx)._ap_fit\n",
    "\n",
    "                    psd_model_fit = data['trial_fooofs'][trial_idx].get_fooof(chan_idx).fooofed_spectrum_\n",
    "                    exponent = data['trial_fooofs'][trial_idx].get_fooof(chan_idx).aperiodic_params_[-1]\n",
    "                    offset = data['trial_fooofs'][trial_idx].get_fooof(chan_idx).aperiodic_params_[0]\n",
    "                    knee = data['trial_fooofs'][trial_idx].get_fooof(chan_idx).aperiodic_params_[1]\n",
    "                    r_squared = data['trial_fooofs'][trial_idx].get_fooof(chan_idx).r_squared_\n",
    "                    \n",
    "                    data_dict = {'psd_raw': psd_raw, \n",
    "                                'psd_corrected': psd_corrected, \n",
    "                                'psd_model_fit': psd_model_fit, \n",
    "                                'exponent': exponent, \n",
    "                                'offset': offset, \n",
    "                                'knee': knee, \n",
    "                                'r_squared': r_squared,\n",
    "                                'info': data['info'][trial_idx]}\n",
    "                    \n",
    "                    magic_dict.append(data_dict)\n",
    "            fname_output = fname.replace('.pkl', '_magic.pkl')\n",
    "            with open(fname_output, 'wb') as f:\n",
    "                pickle.dump(magic_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic_dict_fname = '../tmp/magic_dict.pkl'\n",
    "with open(magic_dict_fname, 'wb') as f:\n",
    "    pickle.dump(magic_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'event_idx': 28,\n",
       " 't0_sample': 11537,\n",
       " 'VTC': 0.7225625990604972,\n",
       " 'task': 'correct_commission',\n",
       " 'RT': 0.7529591323536806,\n",
       " 'INOUT': 'OUT',\n",
       " 'INOUT_2575': 'OUT',\n",
       " 'INOUT_1090': nan,\n",
       " 'bad_epoch': False,\n",
       " 'included_bad_epochs': array([False,  True,  True,  True,  True,  True,  True, False]),\n",
       " 'included_events_idx': [11, 14, 17, 19, 21, 23, 25, 28],\n",
       " 'included_VTC': array([0.75137772, 0.4781026 , 0.40111338, 1.42434049, 1.38528246,\n",
       "        1.04770424, 1.06561359, 0.7225626 ]),\n",
       " 'included_task': array(['correct_commission', 'correct_commission', 'correct_commission',\n",
       "        'correct_commission', 'correct_commission', 'correct_commission',\n",
       "        'correct_commission', 'correct_commission'], dtype=object),\n",
       " 'included_RT': array([0.75745433, 0.71482305, 0.70281263, 0.86243741, 0.85634431,\n",
       "        0.80368166, 0.80647554, 0.75295913]),\n",
       " 'included_INOUT': array(['OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT'],\n",
       "       dtype=object),\n",
       " 'included_INOUT_2575': array(['OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT', 'OUT'],\n",
       "       dtype=object),\n",
       " 'included_INOUT_1090': array([nan, nan, nan, nan, nan, nan, nan, nan], dtype=object)}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_data(magic_dict, feature_type='psd_corrected', trial_type=['correct_commission'], ignore_bads=True):\n",
    "    \n",
    "    return X, y, groups, VTC, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sub-04'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magic_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_fpath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39mlistdir(feature_fpath)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_fpath' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "os.listdir(feature_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = op.join('/home/hyruuk/GitHub/cocolab/cc_saflow/tmp/', 'subject_averaged_fooofs.pkl')\n",
    "with open(output_fname, 'rb') as f:\n",
    "    fooof_array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_bands_from_bands(fm, freqs=saflow.FREQS):\n",
    "    fooof_freqs = fm.freqs\n",
    "    original_bands = []\n",
    "    fooof_bands = []\n",
    "    original_corrected = []\n",
    "    for band in freqs:\n",
    "        freq_mask = np.where((fooof_freqs >= band[0]) & (fooof_freqs <= band[1]))[0]\n",
    "        original = np.mean(fm.power_spectrum[freq_mask])\n",
    "        original_bands.append(original)\n",
    "\n",
    "        fooof = np.mean(fm.fooofed_spectrum_[freq_mask])\n",
    "        fooof_bands.append(fooof)\n",
    "\n",
    "        corrected = fm.power_spectrum - fm._ap_fit\n",
    "        original_corrected.append(np.mean(corrected[freq_mask]))\n",
    "    \n",
    "    exponent = fm.get_params('aperiodic_params', 'exponent')\n",
    "    offset = fm.get_params('aperiodic_params', 'offset')\n",
    "    r_squared = fm.get_params('r_squared')\n",
    "    return original_bands, fooof_bands, original_corrected, exponent, offset, r_squared\n",
    "\n",
    "def get_data_matrix(fooof_array):\n",
    "    original_bands_array = []\n",
    "    fooof_bands_array = []\n",
    "    original_corrected_array = []\n",
    "    exponent_array = []\n",
    "    offset_array = []\n",
    "    r_squared_array = []\n",
    "\n",
    "    for cond_idx in range(fooof_array.shape[0]):\n",
    "        original_bands_subj = []\n",
    "        fooof_bands_subj = []\n",
    "        original_corrected_subj = []\n",
    "        exponent_subj = []\n",
    "        offset_subj = []\n",
    "        r_squared_subj = []\n",
    "        for subj_idx in range(fooof_array.shape[1]):\n",
    "            original_bands_chans = []\n",
    "            fooof_bands_chans = []\n",
    "            original_corrected_chans = []\n",
    "            exponent_chans = []\n",
    "            offset_chans = []\n",
    "            r_squared_chans = []\n",
    "            for chan_idx in range(fooof_array.shape[2]):\n",
    "                fm = fooof_array[cond_idx, subj_idx, chan_idx]\n",
    "                original_bands, fooof_bands, original_corrected, exponent, offset, r_squared = average_bands_from_bands(fm)\n",
    "                original_bands_chans.append(original_bands)\n",
    "                fooof_bands_chans.append(fooof_bands)\n",
    "                original_corrected_chans.append(original_corrected)\n",
    "                exponent_chans.append(exponent)\n",
    "                offset_chans.append(offset)\n",
    "                r_squared_chans.append(r_squared)\n",
    "            original_bands_subj.append(original_bands_chans)\n",
    "            fooof_bands_subj.append(fooof_bands_chans)\n",
    "            original_corrected_subj.append(original_corrected_chans)\n",
    "            exponent_subj.append(exponent_chans)\n",
    "            offset_subj.append(offset_chans)\n",
    "            r_squared_subj.append(r_squared_chans)\n",
    "        original_bands_array.append(original_bands_subj)\n",
    "        fooof_bands_array.append(fooof_bands_subj)\n",
    "        original_corrected_array.append(original_corrected_subj)\n",
    "        exponent_array.append(exponent_subj)\n",
    "        offset_array.append(offset_subj)\n",
    "        r_squared_array.append(r_squared_subj)\n",
    "\n",
    "        data = {'original_bands': np.array(original_bands_array),\n",
    "                'fooof_bands': np.array(fooof_bands_array),\n",
    "                'original_corrected': np.array(original_corrected_array),\n",
    "                'exponent': np.array(exponent_array),\n",
    "                'offset': np.array(offset_array),\n",
    "                'r_squared': np.array(r_squared_array)}\n",
    "    return data\n",
    "\n",
    "data = get_data_matrix(fooof_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 32, 270, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['original_bands'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data_for_classif(data, feature='original_bands'):\n",
    "    X = []\n",
    "    y = []\n",
    "    groups = []\n",
    "    for cond_idx in range(data[feature].shape[0]):\n",
    "        for subj_idx in range(data[feature].shape[1]):\n",
    "            X.append(data[feature][cond_idx, subj_idx])\n",
    "            y.append(cond_idx)\n",
    "            groups.append(subj_idx)\n",
    "    X = np.array(X).transpose(2, 0, 1)\n",
    "    y = np.array(y)\n",
    "    groups = np.array(groups)\n",
    "    return X, y, groups\n",
    "\n",
    "X, y, groups = format_data_for_classif(data, feature='original_bands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_avg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_contrast, tvals, pvals \u001b[39m=\u001b[39m simple_contrast(X, y, groups)\n",
      "\u001b[1;32m/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Average each condition separately\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_avg_by_cond \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m cond \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39munique(y_avg):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     X_avg_by_cond\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(X_avg[y_avg \u001b[39m==\u001b[39m cond], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/hyruuk/GitHub/cocolab/cc_saflow/notebooks/NBX_averaged_fooofs.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Compute normalized contrast (A - B)/B\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_avg' is not defined"
     ]
    }
   ],
   "source": [
    "X_contrast, tvals, pvals = simple_contrast(X, y, groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_contrast(X, y, groups):\n",
    "    \"\"\"Computes subject-averages and contrasts between conditions.\"\"\"\n",
    "    n_features = X.shape[0]\n",
    "    # Average each condition separately\n",
    "    X_avg_by_cond = []\n",
    "    for cond in np.unique(y):\n",
    "        X_avg_by_cond.append(np.mean(X[y == cond], axis=0))\n",
    "    # Compute normalized contrast (A - B)/B\n",
    "    X_contrast = (X_avg_by_cond[0] - X_avg_by_cond[1]) / X_avg_by_cond[1]\n",
    "    # Split conditions for ttest\n",
    "    X_condA = X[y == 0]\n",
    "    X_condB = X[y == 1]\n",
    "    \n",
    "    # Compute t-test\n",
    "    tvals = []\n",
    "    pvals = []\n",
    "    for feature_idx in range(n_features):\n",
    "        t, p = stats.ttest_rel(X_condA[:,feature_idx,:], X_condB[:,feature_idx,:], axis=0)\n",
    "        tvals.append(t)\n",
    "        pvals.append(p)\n",
    "    tvals = np.array(tvals)\n",
    "    pvals = np.array(pvals)\n",
    "    return X_contrast, tvals, pvals\n",
    "\n",
    "\n",
    "def singlefeat_classif(clf, cv, X, y, groups, n_perms=1):\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    cv = LeaveOneGroupOut()\n",
    "\n",
    "    all_scores, all_perm_scores, all_pvals = [], [], []\n",
    "    for freq_idx in range(X.shape[0]):\n",
    "        scores, perm_scores, pvals = [], [], []\n",
    "        for chan_idx in range(X.shape[-1]):\n",
    "            X_sf = X[freq_idx,:,chan_idx]\n",
    "            score, permutation_scores, pvalue = permutation_test_score(clf, X=X_sf.reshape(-1, 1), y=y, groups=groups, cv=cv, n_permutations=n_perms, n_jobs=-1)\n",
    "            scores.append(score)\n",
    "            perm_scores.append(permutation_scores)\n",
    "            pvals.append(pvalue)\n",
    "            print(f'Computed feature {freq_idx} chan {chan_idx} Score {score}, pvalue {pvalue}')\n",
    "        all_scores.append(scores)\n",
    "        all_perm_scores.append(perm_scores)\n",
    "        all_pvals.append(pvals)\n",
    "        \n",
    "    all_scores = np.array(all_scores)\n",
    "    all_perm_scores = np.array(all_perm_scores)\n",
    "    all_pvals = np.array(all_pvals)\n",
    "    all_results = {'scores': all_scores, 'perm_scores': all_perm_scores, 'pvals': all_pvals}\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
